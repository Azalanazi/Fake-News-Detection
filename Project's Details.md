

# Fake News Detection using supervised learning approach 


Datasets:

1- Kaggle: Labaled Dataset A. Fake news data: This dataset contains a list of articles considered "fake" news B. Real news data: This dataset contains a list of articles considered ‚Äùreal" news They both will be merged together with a label binary column "Fake" or "Real"

# Details:

In this project, we will be working on several datasets the first is labeled data and the other is an article that I pulled from a website. Then, another data that crawled from Reddit platform was added because the article data did not too much text in it.
For the part one, because the first data is labeled, we will analyze and prepare it and then use it to train and test the supervised algorithm/s and then will apply the same pretrained algorithm/s to the other dataset in order to detect if it contains fake news, we will see how much fake news in them later in the end of the analysis


# About Dataset
This data set consists of 40000 fake and real news. Our goal is to train our model to accurately predict whether a particular piece of news is real or fake. Fake and real news data are given in two separate data sets, with each data set consisting of approximately 20000 articles.
The data is here "https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset" 
The altered and pre-processed data is provided in a CSV file in the data file. 

2- Web Scraping:
A. An article pulled from CNN Politics. The data can be found here: https://edition.cnn.com/2022/09/16/politics/donald-trump-hugh-hewitt-interview-indicted/index.html 
B. Political posts and news from Reddit Platform: is given in a csv file in the data file. 




